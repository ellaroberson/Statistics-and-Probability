{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ellaroberson/Statistics-and-Probability/blob/main/Ella_lab_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJjTOJXQY7L2"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install wandb #is a tool for visualizing and tracking machine\n",
        "#learning experiments.\n",
        "!apt-get install poppler-utils #poppler-utils is a set of utilities for working\n",
        "#with PDF files, such as extracting text, images\n",
        "# and other information from PDF documents.\n",
        "!pip install pdf2image #converts PDF files into images\n",
        "!pip install flashtorch #provides tools for visualizing activations, gradients,\n",
        "#and filters within deep neural networks, aiding in the interpretation\n",
        "import requests # library is used for making HTTP requests in Python\n",
        "from pdf2image import convert_from_path # convert pages of a PDF file into images.\n",
        "import matplotlib.pyplot as plt # creating visualizations in Python\n",
        "import numpy as np\n",
        "import torch\n",
        "import requests\n",
        "from torchvision import * #This is a package in PyTorch that consists of popular\n",
        "# datasets, model architectures,\n",
        "#and common image transformations for computer vision tasks.\n",
        "from torchvision.models import *\n",
        "import wandb as wb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcM-MSMRmAXL"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "#This line checks if a CUDA-enabled GPU is available\n",
        "#If a GPU is available, it sets the device variable to \"cuda:0\",\n",
        "#indicating that computations should be performed on the GPU.\n",
        "#If no GPU is available, it sets device to \"cpu\", indicating that computations\n",
        "#should be performed on the CPU.\n",
        "def GPU(data):\n",
        "    return torch.tensor(data, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "def GPU_data(data):\n",
        "    return torch.tensor(data, requires_grad=False, dtype=torch.float, device=device)\n",
        "#These functions help streamline the process of creating PyTorch tensors on the\n",
        "# appropriate device (CPU or GPU) while also managing whether gradients need to\n",
        "#be tracked for those tensors\n",
        "def plot(x):\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(x, cmap = 'gray')\n",
        "    ax.axis('off')\n",
        "    fig.set_size_inches(5, 5)\n",
        "    plt.show()\n",
        "\n",
        "def get_google_slide(url): # takes a URL of a Google Slides presentation as input\n",
        "#and returns a URL that can be used to download the presentation as a PDF file.\n",
        "    url_head = \"https://docs.google.com/presentation/d/\" #stores the beginning part of the URL\n",
        "    url_body = url.split('/')[5] #This line splits the input URL by / and extracts\n",
        "    # the part of the URL that contains the unique identifier for the Google Slides presentation.\n",
        "    #This part of the URL is typically after the fifth / occurrence.\n",
        "    page_id = url.split('.')[-1]\n",
        "    return url_head + url_body + \"/export/pdf?id=\" + url_body + \"&pageid=\" + page_id\n",
        "    #the function returns the generated URL.\n",
        "\n",
        "def get_slides(url): #converts each page of the PDF into images from the previous url\n",
        "    url = get_google_slide(url) #transforms to a pdf\n",
        "    r = requests.get(url, allow_redirects=True) #It allows redirects\n",
        "    open('file.pdf', 'wb').write(r.content) #writes the content of the HTTP response\n",
        "     #(r.content) to the file.\n",
        "    images = convert_from_path('file.pdf', 500) #The function takes two arguments:\n",
        "    # the path to the PDF file ('file.pdf') and the resolution (500 DPI in this case).\n",
        "    return images\n",
        "\n",
        "def load(image, size=224): #image, which represents the input image to be\n",
        "    \"\"\"\n",
        "\n",
        "    Args:\n",
        "      image:\n",
        "      size:\n",
        "\n",
        "    Returns:\n",
        "\n",
        "    \"\"\"\n",
        "#processed, and size, which specifies the desired size for the image after preprocessing\n",
        "    means = [0.485, 0.456, 0.406]\n",
        "    stds = [0.229, 0.224, 0.225]\n",
        "    #These lines define the mean and standard deviation values for normalization.\n",
        "    transform = transforms.Compose([ #creates a series of image transformations\n",
        "        transforms.Resize(size),\n",
        "        transforms.CenterCrop(size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(means, stds)\n",
        "    ])\n",
        "    tensor = transform(image).unsqueeze(0).to(device)\n",
        "    tensor.requires_grad = True\n",
        "    return tensor\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opN3hI0lemBV"
      },
      "outputs": [],
      "source": [
        "labels = {int(key):value for (key, value) in requests.get('https://s3.amazonaws.com/mlpipes/pytorch-quick-start/labels.json').json().items()}\n",
        "#This line makes an HTTP GET request to the specified URL, which contains a JSON file (labels.json). The JSON file likely contains a mapping of class indices to class labels for the model's output.\n",
        "model = alexnet(weights='DEFAULT').to(device)\n",
        "#This function call creates an instance of the AlexNet model.This method moves the model to the specified device (device). If device is set to a GPU, the model will be transferred to the GPU; otherwise, it will remain on the CPU.\n",
        "model.eval(); #changes the behavior of certain layers, such as dropout and batch normalization layers, to ensure consistent behavior during inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EnZVMTqiqwz"
      },
      "outputs": [],
      "source": [
        "url = \"https://docs.google.com/presentation/d/17Nxy2Wo0erk71fp4sCDQqHrHYkxwjdExjbosjoEewuU/edit#slide=id.p\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7MhH8hrR3AE"
      },
      "outputs": [],
      "source": [
        "images = [] #store the processed images\n",
        "\n",
        "for image in get_slides(url):\n",
        "\n",
        "    plot(image)\n",
        "\n",
        "    images.append(load(image))\n",
        "\n",
        "images = torch.vstack(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKsUVAPdQwmP"
      },
      "outputs": [],
      "source": [
        "images.shape\n",
        "#you can understand the size and structure of the tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJlgt1avR3I9"
      },
      "outputs": [],
      "source": [
        "model(images) #produces the model's predictions or outputs for the given batch of images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgGzMREYR3LN"
      },
      "outputs": [],
      "source": [
        "y = model(images) #sets that equal to y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3NVy8_7T_rb"
      },
      "outputs": [],
      "source": [
        "y.shape #gives the y shape dimensions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsYfYT6UR3Nn"
      },
      "outputs": [],
      "source": [
        "guesses = torch.argmax(y, 1).cpu().numpy()\n",
        "#torch.argmax(y, 1) means y is likely the output of the neural network, and 1 indicates that the maximum value should be searched for along dimension 1\n",
        "#cpu(): This method moves the tensor from the GPU (if it was computed on the GPU) to the CPU\n",
        "#.numpy(): This method converts the tensor to a NumPy array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvSec8rITW7T"
      },
      "outputs": [],
      "source": [
        "for i in list(guesses): #This loop iterates over each element (i) in the guesses list.\n",
        "    print(labels[i]) #prints the class label corresponding to the current predicted class index (i)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CALvf79gjAY-"
      },
      "outputs": [],
      "source": [
        "Y = np.zeros(50,)\n",
        "Y[25:] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcBPB-F_jh9H"
      },
      "outputs": [],
      "source": [
        "Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzGPSBiRjTfR"
      },
      "outputs": [],
      "source": [
        "# Y = np.zeros(100,)\n",
        "# Y[50:] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVRYStHJjq-Z"
      },
      "outputs": [],
      "source": [
        "Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqvMEcxhY6dl"
      },
      "outputs": [],
      "source": [
        "X = y.detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqPB9TKyEJCS"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OB9J8q8LEgCG"
      },
      "outputs": [],
      "source": [
        "plt.plot(X[0],'.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cetMFwBQngCQ"
      },
      "outputs": [],
      "source": [
        "plt.hist(X[0]) #enerates a histogram plot of the values in the first element (X[0]) of the array X using Matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBt4rsdIefV_"
      },
      "outputs": [],
      "source": [
        "X = GPU_data(X)\n",
        "Y = GPU_data(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4BlYG-CgC2z"
      },
      "outputs": [],
      "source": [
        "def softmax(x): #computes the softmax activation function for each row of a tensor x.\n",
        "    s1 = torch.exp(x - torch.max(x,1)[0][:,None])\n",
        "    s = s1 / s1.sum(1)[:,None] #This computes the sum of each row of the tensor s1.\n",
        "    return s"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oWclRLmmBzyK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZ-UV8W_c_9o"
      },
      "outputs": [],
      "source": [
        "def cross_entropy(outputs, labels): #computes the cross-entropy loss between the predicted outputs and the true labels\n",
        "    return -torch.sum(softmax(outputs).log()[range(outputs.size()[0]), labels.long()])/outputs.size()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtL1kZcZICVP"
      },
      "outputs": [],
      "source": [
        "def randn_trunc(s): #Truncated Normal Random Numbers\n",
        "    mu = 0 #This sets the mean of the normal distribution to 0.\n",
        "    sigma = 0.1 #sets the standard deviation of the normal distribution to 0.1.\n",
        "    R = stats.truncnorm((-2*sigma - mu) / sigma, (2*sigma - mu) / sigma, loc=mu, scale=sigma)\n",
        "    #line creates a truncated normal distribution using the truncnorm function from the stats module\n",
        "    return R.rvs(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPQjN4JwYHAz"
      },
      "outputs": [],
      "source": [
        "def Truncated_Normal(size): #generates samples from a truncated normal distribution using the Box-Muller transform.\n",
        "\n",
        "    u1 = torch.rand(size)*(1-np.exp(-2)) + np.exp(-2) #This line generates uniform random numbers (u1) in the range (0, 1) using torch.rand(size)\n",
        "    u2 = torch.rand(size) #This line generates another set of uniform random numbers (u2) in the range (0, 1).\n",
        "    z  = torch.sqrt(-2*torch.log(u1)) * torch.cos(2*np.pi*u2)\n",
        "    #This line applies the Box-Muller transform to transform the generated uniform random numbers into samples (z) from a standard normal distribution (mean=0, std=1) with the specified size.\n",
        "\n",
        "    return z"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OJ5izh4tCQJs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LW3ttVcq1sI9"
      },
      "outputs": [],
      "source": [
        "def acc(out,y): #calculates the accuracy of a model's predictions given the predicted outputs (out) and the true labels (y).\n",
        "    with torch.no_grad(): #saves memory and computational resources since gradients are not needed for calculating accuracy.\n",
        "        return (torch.sum(torch.max(out,1)[1] == y).item())/y.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zh2vYJuSC805"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UXgio04fyvz"
      },
      "outputs": [],
      "source": [
        "X.shape #defines dimensions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x79Sie8XKPOC"
      },
      "outputs": [],
      "source": [
        "def get_batch(mode): #used to retrieve a batch of data samples and their corresponding labels for either training or testing purposes.\n",
        "    b = c.b #etrieves the batch size (b) from some external source or configuration object c.\n",
        "    if mode == \"train\": #checks if the requested mode is for training.\n",
        "        r = np.random.randint(X.shape[0]-b) #This random integer represents the starting index of the batch in the training dataset.\n",
        "        x = X[r:r+b,:] #This line selects a batch of input data samples (x) from the training dataset (X) starting from index r and spanning b samples.\n",
        "        y = Y[r:r+b]\n",
        "    elif mode == \"test\": #This condition checks if the requested mode is for testing.\n",
        "        r = np.random.randint(X_test.shape[0]-b)\n",
        "        x = X_test[r:r+b,:]\n",
        "        y = Y_test[r:r+b]\n",
        "    return x,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXOr9aM8A8P-"
      },
      "outputs": [],
      "source": [
        "def model(x,w): #represents a simple linear regression model\n",
        "\n",
        "    return x@w[0] # This line performs matrix multiplication between the input features x and the weights w[0]. The @ operator is used in Python for matrix multiplication (dot product)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzRsuDek9Fve"
      },
      "outputs": [],
      "source": [
        "def make_plots(): #create plots related to model training and performance evaluation.\n",
        "\n",
        "    acc_train = acc(model(x,w),y)\n",
        "\n",
        "    # xt,yt = get_batch('test')\n",
        "\n",
        "    # acc_test = acc(model(xt,w),yt)\n",
        "\n",
        "    wb.log({\"acc_train\": acc_train})\n",
        "    #it logs the training accuracy value (acc_train) to the logging platform under the key \"acc_train\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WANJibeUNghZ"
      },
      "outputs": [],
      "source": [
        "wb.init(project=\"Linear_Model_Photo_1\"); #sets up the experiment environment and connects it to the specified project\n",
        "c = wb.config # assigns the configuration object of the experiment to the variable c.\n",
        "\n",
        "c.h = 0.001 #ets the learning rate (h) in the experiment configuration to 0.001.\n",
        "c.b = 32 #This sets the batch size (b) in the experiment configuration to 32.\n",
        "c.epochs = 100000 #This sets the number of epochs (epochs) in the experiment configuration to 100000.\n",
        "\n",
        "w = [GPU(Truncated_Normal((1000,2)))] #This suggests that the model has 1000 weights for each of the 2 features.\n",
        "\n",
        "optimizer = torch.optim.Adam(w, lr=c.h) #This initializes an Adam optimizer\n",
        " #(torch.optim.Adam) with the model weights w and the learning rate specified in the experiment configuration (c.h).\n",
        "\n",
        "for i in range(c.epochs): #Each epoch represents one pass through the entire training dataset.\n",
        "\n",
        "    x,y = get_batch('train') #This line retrieves a batch of training data samples\n",
        "     #(x) and their corresponding labels (y)\n",
        "\n",
        "    loss = cross_entropy(softmax(model(x,w)),y) #This computes the loss for the current batch of training data\n",
        "\n",
        "    optimizer.zero_grad() #This line zeroes out the gradients of all model parameters before the backward pass.\n",
        "    loss.backward() #computes the gradients of the loss with respect to all model parameters using backpropagation.\n",
        "    optimizer.step() #This updates the model parameters (weights) based on the computed gradients and the optimization algorithm\n",
        "\n",
        "    wb.log({\"loss\": loss}) #This logs the value of the loss for the current iteration to the logging platform (Weights & Biases).\n",
        "\n",
        "    make_plots() #MAKES PLOTS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VGdS4Ccv3ToX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cogMnVmoY6fs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "numPOTfxY6h8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9H5XxYs2Y6jl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dnuZwveTjkLb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Iqz6xc5VjkNo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gfnOAreBjkPo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "M052UNm_OwV5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-iAwNrgSOwX3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "isgUmuudOwaP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "44_in1VIjkRr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}